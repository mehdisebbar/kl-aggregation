from datetime import datetime
import os
from multiprocessing import Pool
import pickle
from time import time
import uuid
import numpy as np
from scipy.stats import multivariate_normal
from sklearn.preprocessing import StandardScaler
from tools import kl_norm, l2_norm, GaussianMixtureGen, mle_bic, KdeCV
from densitiesGenerator import  DensityGenerator
from algorithm import WeightEstimator
from dictionary_generator import DictionaryGenerator
from pypmc.density.mixture import create_gaussian_mixture


"""
We compare the KL-aggregation density estimator with the EM-BIC density estimator
on a problem of clustering/density estimation.
From a sample drawn from a p dimensional Gaussian mixture ok K components, we
generate a dictionary of densities via DensityGenerator class. It performs PCA and
runs kmeans on points projected on all subspaces spanned by 2 components of the PCA.
We runs after the KL-aggregator on those densities and EM+BIC on the original space.
Finally, KL and L2 norms are computed via Importance sampling. Computing times are 
recorded.
"""

N_PDF = 10000
KMEANS_K = 5
MAX_COMPONENTS_MLE_BIC = 20
SAMPLE_SIZE = 10000
MAX_EM_BIC_K = 20
FOLDER = "dg_"+str(datetime.now()).split(".")[0].replace(" ", "_").replace(":", ".") + "/"
os.makedirs(FOLDER)

class KLaggDensity(object):
    """
    Class of the mixture density generated by th KL-aggreg algorithm
    """
    def __init__(self, weights, density_dict):
        self.weights = weights
        self.density_dict = density_dict
    
    def pdf(self, x):
        return  self.weights.dot(np.array([d.pdf(x) for d in self.density_dict]))

class GaussMixtureDensity(object):
    """
    General class for a Gaussian mixture density given weights, centers and cov
    """
    def __init__(self, weights, centers, cov):
        self.weights = weights
        self.centers = centers
        self.cov = cov
    
    def pdf(self, x):
        return self.weights.dot(np.array([multivariate_normal(self.centers[i], self.cov[i]).pdf(x) for i in range(len(self.weights))]))


class IntegrandL2Density(object):
    """
    Compute the integrand (1-g/f)^2*f, f sampling distrib known, g estimator of density.
    """
    def __init__(self, f, g):
        """
        f and g are pdf functions
        """
        self.f = f
        self.g = g

    def pdf(self, x):
        return (1-self.g(x)/self.f(x))**2*self.f(x)

class IntegrandKLDensity(object):
    """
    Compute the integrand log(f/g), f sampling distrib known, g estimator of density.
    """
    def __init__(self, f, g):
        """
        f and g are pdf functions
        """
        self.f = f
        self.g = g

    def pdf(self, x):
        return np.log(self.f(x)/self.g(x))

class BasicGen(object):
    #dirty gross generator
    def __init__(self, dim=5):
        self.dim = dim
        self.params = [
            (np.array([[3, 0, 0, 0, 0],
                      [0, 0.1, 0, 0, 0],
                      [0, 0, 0.1, 0, 0],
                      [0, 0, 0, 0.1, 1],
                      [0, 0, 0, 1, 3]]), 
             np.array([0.1, 0.1, 0.1, 0.1, 0.1])), 
            (np.array([[0.1, 0, 0, 0, 0],
                            [0, 2, -0.2, 0, 0],
                            [0, -0.2, 0.1, 0, 0],
                            [0, 0, 0, 0.1, 0],
                            [0, 0, 0, 0, 1]]),
             np.array([0.8, 0.8, 0.8, 0.8, 0.8])), 
            (np.array([[1, 0.1, 1.9, 0, 0],
                       [0.1, 0.5, -1, 0, 0],
                       [1.9, -1, 3, 0, 0],
                       [0, 0, 0, 0.1, 0],
                       [0, 0, 0, 0, 0.1]]),
             np.array([0.1, 0.4, 0.6, 0.8, 0.1])),
            (np.array([[0.5, 1, -1, 0, 0],
                       [1, 2, 0, 0, 0],
                       [-1, 0, 0.1, 0, 0],
                       [0, 0, 0, 1, 0],
                       [0, 0, 0, 0, 0.1]]),
             np.array([0.5, 0.8, 0.4, 0.4, 0.4])),
            (np.array([[4, 0, 0, 0, 0],
                       [0, 0.5, 0, 0, 0],
                       [0, 0, 0.2, 0, 0],
                       [0, 0, 0, 0.2, 0],
                       [0, 0, 0, 0, 0.2]]),
             np.array([0.9, 0.2, 0.9, 0.9, 0.9])),
            (np.array([[0.1, 0, -1, 0, 0],
                       [0,  6, 0,   0, 0],
                       [-1, 0, 0.1, 0, 0],
                       [0, 0, 0, 0.1, 0],
                       [0, 0, 0, 0, 0.1]]),
             np.array([1, 0.8, 0.2, 0.4, 0.4]))
        ]
        self.change_dim(self.dim)
        self.means, self.variances = zip(*self.params)
    
    def change_dim(self, p):
        params = []
        for cov, m in self.params:
            C = cov[:p,:p]
            params.append((m[:p], 1e-3*C.T.dot(C)))
        self.params = params
    
    def get_params(self):
        return self.means, self.variances
    
    def sample(self, N, with_ids = False):
        #We generate a dataset with specific data
        K = len(self.params)
        X = multivariate_normal(self.params[0][0], self.params[0][1]).rvs(N/K)
        ids = np.ones(N/K)
        i = 2
        for m, cov in self.params[1:]:
            X = np.vstack([X, multivariate_normal(m, cov).rvs(N/K)])
            ids = np.hstack([ids, i*np.ones(N/K)])
            i+=1
        if with_ids:
            X = np.hstack([X, ids.reshape(-1,1)])
        np.random.shuffle(X)
        return X

class BasicGenD3(object):
    #Only dim 3
    def __init__(self, dim):
        self.covs = 1e-3*np.array([
            np.array([[10, 0, 3],
                      [0, 0.1, 0],
                      [3, 0, 1]]),
                  
            np.array([[0.1,0,0],
                      [0, 2 ,-4],
                      [0, -4, 10]]),
                  
            np.array([[0.1, 0.3, 0],
                      [0.3, 20, 0],
                      [0, 0, 0.5]]),
            ])
        self.means = [
            np.array([0.1, 0.1, 0.1]),
            np.array([0.1, 0.8 , 0.8]),
            np.array([0.6, 0.2, 0.8]),
            ]
    def sample(self, N, with_ids = False):
        X = multivariate_normal(self.means[0], self.covs[0]).rvs(N/3)
        ids = np.ones(N/3)
        X = np.vstack([X, multivariate_normal(self.means[1], self.covs[1]).rvs(N/3)])
        ids = np.hstack([ids, 2*np.ones(N/3)])
        X = np.vstack([X, multivariate_normal(self.means[2], self.covs[2]).rvs(N/3)])
        ids = np.hstack([ids, 3*np.ones(N/3)])
        if with_ids:
            X = np.hstack([X, ids.reshape(-1,1)])
        np.random.shuffle(X)
        return X

    def get_params(self):
        return self.means, self.covs

def simu(N, K, dim):
    try:
        #Some initialization
        sc = StandardScaler()
        
        max_pca_comp = dim/2+1
        # We generate the Gaussian mixture
        #gg = GaussianMixtureGen(dim, weights)
        #centers_star, cov_star = gg.get_params()
        gg = BasicGenD3(dim)
        centers_star, cov_star = gg.get_params()
        #X_ = gg.sample(N)
        X_ids = gg.sample(N, with_ids=True)
        ids = X_ids[:,-1]
        X_ = X_ids[:,:-1]
        K = len(set(ids))
        weights = 1./K*np.ones(K)
        #We normalize the data for the PCA in the KL aggreg
        X = sc.fit_transform(X_)
        #We generate the target density f_star from the components
        f_star = GaussMixtureDensity(weights, centers_star, cov_star)
        f_star_sampling = create_gaussian_mixture(centers_star, cov_star, weights)
        ######################
        # KL-AGGREG. ALGORITHM
        ######################
        time_kl_aggreg_start = time()
        dg = DictionaryGenerator(kmeans_k=KMEANS_K, max_pca_comp=max_pca_comp, subspace_cluster_dim=2)
        densities_dict = dg.fit_transform(X)
        cl = WeightEstimator(densities_dict=densities_dict)
        cl.fit(X)
        time_kl_aggreg_stop = time()
        kl_aggreg_weights = cl.pi_final
        kl_aggreg_density = KLaggDensity(kl_aggreg_weights, densities_dict)
        #Compute L2 loss
        kl_aggreg_integrand_L2_loss = IntegrandL2Density(f_star.pdf, kl_aggreg_density.pdf)
        kl_aggreg_l2 = l2_norm(kl_aggreg_integrand_L2_loss.pdf, f_star_sampling, sample_size=SAMPLE_SIZE)
        #Compute KL loss
        kl_aggreg_integrand_KL_loss = IntegrandKLDensity(f_star.pdf, kl_aggreg_density.pdf)
        kl_aggreg_kl = kl_norm(kl_aggreg_integrand_KL_loss.pdf, f_star_sampling, sample_size=SAMPLE_SIZE)
        #################
        #EM-BIC ALGORITHM
        #################
        time_em_start = time()
        _, em_model = mle_bic(X, MAX_EM_BIC_K)
        time_em_stop = time()
        em_density = GaussMixtureDensity(em_model.weights_, em_model.means_, em_model.covariances_)
        #Compute L2 loss
        em_integrand_L2_loss = IntegrandL2Density(f_star.pdf, em_density.pdf)
        em_l2 = l2_norm(em_integrand_L2_loss.pdf, f_star_sampling, sample_size=SAMPLE_SIZE)
        #Compute KL loss
        em_integrand_KL_loss = IntegrandKLDensity(f_star.pdf, em_density.pdf)
        em_kl = kl_norm(em_integrand_KL_loss.pdf, f_star_sampling, sample_size = SAMPLE_SIZE)
        #################
        #KDE-CV ALGORITHM
        #################
        kde = KdeCV(n_jobs = 1, cv=10, bw = np.linspace(0.01, 1.0, 20))
        time_kde_start = time()
        kde.fit(X)
        time_kde_stop = time()
        kde_integrand_KL_loss = IntegrandKLDensity(f_star.pdf, kde.pdf)
        kde_kl = kl_norm(kde_integrand_KL_loss.pdf, f_star_sampling, sample_size = SAMPLE_SIZE)   
        kde_integrand_L2_loss = IntegrandL2Density(f_star.pdf, kde.pdf)
        kde_l2 = l2_norm(kde_integrand_L2_loss.pdf, f_star_sampling, sample_size=SAMPLE_SIZE)  
        #Compute times
        kl_aggreg_time = time_kl_aggreg_stop-time_kl_aggreg_start
        em_bic_time = time_em_stop-time_em_start
        kde_cv_time = time_kde_stop-time_kde_start
        #Writing results
        print "OK, writing results"
        pickle.dump({"K" : K,
                     "p" : dim,
                     "N" : N,
                     "MLE_l2" : kl_aggreg_l2,
                     "MLE_KL" : kl_aggreg_kl,
                     "MLE_time" : kl_aggreg_time,
                     "EM_l2" : em_l2,
                     "EM_KL" : em_kl,
                     "EM_time" : em_bic_time,
                     "KdeCV_l2" : kde_l2,
                     "KdeCV_KL" : kde_kl,
                     "KdeCV_time" : kde_cv_time
                 }, open(FOLDER +
                         "res_" + "K" + str(K) + "p" + str(dim) + "N" + str(N) +"_"+ str(uuid.uuid4()), "wb"))
        return 1
    except Exception as e:
        print e
        return 0


if __name__ == "__main__":
    print FOLDER
#    simu_list = [
#        (2,2,100),
#        (4,2,100),
#        (4,2,500),
#        (4,5,100),
#        (4,5,500),
#        (4,5,1000)
#        #(10,5,100),
#        #(10,5,500),
#        #(10,5,1000),
#        #(10,20,500),
#        #(10,20,1000)
#    ]
#   for K, dim, N in simu_list:
#       if K > 2**dim:
#           pass
#       else:
#           p = Pool(processes=8) 
#           i=0
#           #We send a batch of 20 tasks
#           while i <=100:
#               res = [p.apply_async(simu, args=(N, K, dim)) for _ in range(20)]
#               i += sum([r.get() for r in res])
#           p.close()
#           p.join()        
    for dim in [3]:
        for N in [100, 500, 1000]:
            p = Pool(processes=8) 
            i=0
            #We send a batch of 20 tasks
            while i <=100:
                res = [p.apply_async(simu, args=(N, 4, dim)) for _ in range(20)]
                i += sum([r.get() for r in res])
            p.close()
            p.join() 